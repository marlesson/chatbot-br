{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from gensim import models\n",
    "from keras.layers import LSTM, SimpleRNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "import pickle\n",
    "\n",
    "# w2v_en = models.Word2Vec.load('word2vec.bin');\n",
    "# w2v_br = models.KeyedVectors.load_word2vec_format(\"wiki.pt.trigram.vector\", binary=True)\n",
    "w2v = models.KeyedVectors.load_word2vec_format(\"cbow_s50.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('conversation_br.pickle', 'rb') as f:\n",
    "    vec_x, vec_y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_x = np.array(vec_x, dtype=np.float32)\n",
    "vec_y = np.array(vec_y, dtype=np.float32)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(vec_x, vec_y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 15, 400)           721600    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 15, 50)            90200     \n",
      "=================================================================\n",
      "Total params: 811,800\n",
      "Trainable params: 811,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=Sequential()\n",
    "model.add(LSTM(400, input_shape=x_train.shape[1:], return_sequences=True, kernel_initializer='glorot_normal', recurrent_initializer='glorot_normal', activation='sigmoid'))\n",
    "#model.add(LSTM(400, return_sequences=True, kernel_initializer='glorot_normal', recurrent_initializer='glorot_normal', activation='sigmoid'))\n",
    "#model.add(LSTM(400, return_sequences=True, kernel_initializer='glorot_normal', recurrent_initializer='glorot_normal', activation='sigmoid'))\n",
    "model.add(LSTM(50, return_sequences=True, kernel_initializer='glorot_normal', recurrent_initializer='glorot_normal', activation='sigmoid'))\n",
    "model.compile(loss='cosine_proximity', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68 samples, validate on 18 samples\n",
      "Epoch 1/500\n",
      "68/68 [==============================] - 2s 25ms/step - loss: -0.5741 - acc: 0.0088 - val_loss: -0.5283 - val_acc: 0.0259\n",
      "Epoch 2/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.5779 - acc: 0.0294 - val_loss: -0.5322 - val_acc: 0.0222\n",
      "Epoch 3/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.5825 - acc: 0.0245 - val_loss: -0.5367 - val_acc: 0.0259\n",
      "Epoch 4/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.5864 - acc: 0.0255 - val_loss: -0.5400 - val_acc: 0.0259\n",
      "Epoch 5/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.5889 - acc: 0.0294 - val_loss: -0.5429 - val_acc: 0.0296\n",
      "Epoch 6/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.5912 - acc: 0.0343 - val_loss: -0.5457 - val_acc: 0.0296\n",
      "Epoch 7/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.5940 - acc: 0.0343 - val_loss: -0.5485 - val_acc: 0.0296\n",
      "Epoch 8/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.5964 - acc: 0.0304 - val_loss: -0.5510 - val_acc: 0.0148\n",
      "Epoch 9/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.5983 - acc: 0.0196 - val_loss: -0.5529 - val_acc: 0.0037\n",
      "Epoch 10/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.5999 - acc: 0.0029 - val_loss: -0.5560 - val_acc: 0.0037\n",
      "Epoch 11/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6020 - acc: 0.0029 - val_loss: -0.5589 - val_acc: 0.0037\n",
      "Epoch 12/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6036 - acc: 0.0039 - val_loss: -0.5606 - val_acc: 0.0259\n",
      "Epoch 13/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6050 - acc: 0.0294 - val_loss: -0.5612 - val_acc: 0.0222\n",
      "Epoch 14/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6061 - acc: 0.0108 - val_loss: -0.5623 - val_acc: 0.0037\n",
      "Epoch 15/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6073 - acc: 0.0039 - val_loss: -0.5632 - val_acc: 0.0037\n",
      "Epoch 16/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6085 - acc: 0.0029 - val_loss: -0.5645 - val_acc: 0.0037\n",
      "Epoch 17/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6096 - acc: 0.0029 - val_loss: -0.5647 - val_acc: 0.0111\n",
      "Epoch 18/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6100 - acc: 0.0186 - val_loss: -0.5640 - val_acc: 0.0296\n",
      "Epoch 19/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6110 - acc: 0.0333 - val_loss: -0.5661 - val_acc: 0.0333\n",
      "Epoch 20/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6117 - acc: 0.0245 - val_loss: -0.5678 - val_acc: 0.0074\n",
      "Epoch 21/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6126 - acc: 0.0049 - val_loss: -0.5690 - val_acc: 0.0037\n",
      "Epoch 22/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6141 - acc: 0.0049 - val_loss: -0.5695 - val_acc: 0.0037\n",
      "Epoch 23/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6148 - acc: 0.0039 - val_loss: -0.5709 - val_acc: 0.0037\n",
      "Epoch 24/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6159 - acc: 0.0049 - val_loss: -0.5723 - val_acc: 0.0296\n",
      "Epoch 25/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6171 - acc: 0.0304 - val_loss: -0.5715 - val_acc: 0.0333\n",
      "Epoch 26/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6179 - acc: 0.0333 - val_loss: -0.5714 - val_acc: 0.0296\n",
      "Epoch 27/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6189 - acc: 0.0324 - val_loss: -0.5738 - val_acc: 0.0259\n",
      "Epoch 28/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6187 - acc: 0.0216 - val_loss: -0.5753 - val_acc: 0.0037\n",
      "Epoch 29/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6200 - acc: 0.0029 - val_loss: -0.5729 - val_acc: 0.0111\n",
      "Epoch 30/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6197 - acc: 0.0186 - val_loss: -0.5757 - val_acc: 0.0259\n",
      "Epoch 31/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6212 - acc: 0.0255 - val_loss: -0.5766 - val_acc: 0.0296\n",
      "Epoch 32/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6208 - acc: 0.0284 - val_loss: -0.5778 - val_acc: 0.0222\n",
      "Epoch 33/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6215 - acc: 0.0216 - val_loss: -0.5761 - val_acc: 0.0074\n",
      "Epoch 34/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6212 - acc: 0.0147 - val_loss: -0.5747 - val_acc: 0.0074\n",
      "Epoch 35/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6219 - acc: 0.0176 - val_loss: -0.5765 - val_acc: 0.0111\n",
      "Epoch 36/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6223 - acc: 0.0235 - val_loss: -0.5781 - val_acc: 0.0296\n",
      "Epoch 37/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6226 - acc: 0.0343 - val_loss: -0.5776 - val_acc: 0.0222\n",
      "Epoch 38/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6226 - acc: 0.0314 - val_loss: -0.5751 - val_acc: 0.0185\n",
      "Epoch 39/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6227 - acc: 0.0088 - val_loss: -0.5772 - val_acc: 0.0037\n",
      "Epoch 40/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6236 - acc: 0.0049 - val_loss: -0.5775 - val_acc: 0.0074\n",
      "Epoch 41/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6234 - acc: 0.0196 - val_loss: -0.5776 - val_acc: 0.0222\n",
      "Epoch 42/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6242 - acc: 0.0324 - val_loss: -0.5781 - val_acc: 0.0296\n",
      "Epoch 43/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6243 - acc: 0.0333 - val_loss: -0.5790 - val_acc: 0.0296\n",
      "Epoch 44/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6248 - acc: 0.0333 - val_loss: -0.5803 - val_acc: 0.0296\n",
      "Epoch 45/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6247 - acc: 0.0314 - val_loss: -0.5798 - val_acc: 0.0185\n",
      "Epoch 46/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6251 - acc: 0.0235 - val_loss: -0.5784 - val_acc: 0.0148\n",
      "Epoch 47/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6248 - acc: 0.0216 - val_loss: -0.5788 - val_acc: 0.0111\n",
      "Epoch 48/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6249 - acc: 0.0225 - val_loss: -0.5793 - val_acc: 0.0259\n",
      "Epoch 49/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6255 - acc: 0.0304 - val_loss: -0.5765 - val_acc: 0.0222\n",
      "Epoch 50/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6255 - acc: 0.0265 - val_loss: -0.5754 - val_acc: 0.0148\n",
      "Epoch 51/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6256 - acc: 0.0196 - val_loss: -0.5772 - val_acc: 0.0185\n",
      "Epoch 52/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6259 - acc: 0.0137 - val_loss: -0.5795 - val_acc: 0.0148\n",
      "Epoch 53/500\n",
      "68/68 [==============================] - 0s 3ms/step - loss: -0.6259 - acc: 0.0176 - val_loss: -0.5791 - val_acc: 0.0148\n",
      "Epoch 54/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6261 - acc: 0.0216 - val_loss: -0.5790 - val_acc: 0.0185\n",
      "Epoch 55/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6262 - acc: 0.0265 - val_loss: -0.5802 - val_acc: 0.0296\n",
      "Epoch 56/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6259 - acc: 0.0324 - val_loss: -0.5777 - val_acc: 0.0222\n",
      "Epoch 57/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6256 - acc: 0.0255 - val_loss: -0.5734 - val_acc: 0.0185\n",
      "Epoch 58/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6257 - acc: 0.0206 - val_loss: -0.5775 - val_acc: 0.0222\n",
      "Epoch 59/500\n",
      "68/68 [==============================] - 1s 8ms/step - loss: -0.6258 - acc: 0.0275 - val_loss: -0.5792 - val_acc: 0.0222\n",
      "Epoch 60/500\n",
      "68/68 [==============================] - 1s 9ms/step - loss: -0.6255 - acc: 0.0255 - val_loss: -0.5794 - val_acc: 0.0185\n",
      "Epoch 61/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6264 - acc: 0.0265 - val_loss: -0.5794 - val_acc: 0.0185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6263 - acc: 0.0314 - val_loss: -0.5773 - val_acc: 0.0185\n",
      "Epoch 63/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6268 - acc: 0.0304 - val_loss: -0.5762 - val_acc: 0.0185\n",
      "Epoch 64/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6267 - acc: 0.0275 - val_loss: -0.5763 - val_acc: 0.0259\n",
      "Epoch 65/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6269 - acc: 0.0373 - val_loss: -0.5767 - val_acc: 0.0222\n",
      "Epoch 66/500\n",
      "68/68 [==============================] - 1s 8ms/step - loss: -0.6272 - acc: 0.0402 - val_loss: -0.5772 - val_acc: 0.0185\n",
      "Epoch 67/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6272 - acc: 0.0402 - val_loss: -0.5778 - val_acc: 0.0074\n",
      "Epoch 68/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6275 - acc: 0.0363 - val_loss: -0.5797 - val_acc: 0.0037\n",
      "Epoch 69/500\n",
      "68/68 [==============================] - 1s 8ms/step - loss: -0.6278 - acc: 0.0363 - val_loss: -0.5801 - val_acc: 0.0037\n",
      "Epoch 70/500\n",
      "68/68 [==============================] - 1s 8ms/step - loss: -0.6279 - acc: 0.0265 - val_loss: -0.5799 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6280 - acc: 0.0225 - val_loss: -0.5798 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6281 - acc: 0.0235 - val_loss: -0.5792 - val_acc: 0.0037\n",
      "Epoch 73/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6282 - acc: 0.0314 - val_loss: -0.5781 - val_acc: 0.0148\n",
      "Epoch 74/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6281 - acc: 0.0510 - val_loss: -0.5798 - val_acc: 0.0259\n",
      "Epoch 75/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6286 - acc: 0.0529 - val_loss: -0.5793 - val_acc: 0.0185\n",
      "Epoch 76/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6287 - acc: 0.0510 - val_loss: -0.5793 - val_acc: 0.0148\n",
      "Epoch 77/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6289 - acc: 0.0451 - val_loss: -0.5822 - val_acc: 0.0037\n",
      "Epoch 78/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6286 - acc: 0.0294 - val_loss: -0.5817 - val_acc: 0.0037\n",
      "Epoch 79/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6293 - acc: 0.0343 - val_loss: -0.5782 - val_acc: 0.0074\n",
      "Epoch 80/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6287 - acc: 0.0382 - val_loss: -0.5807 - val_acc: 0.0074\n",
      "Epoch 81/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6291 - acc: 0.0422 - val_loss: -0.5820 - val_acc: 0.0074\n",
      "Epoch 82/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6298 - acc: 0.0373 - val_loss: -0.5786 - val_acc: 0.0037\n",
      "Epoch 83/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6293 - acc: 0.0324 - val_loss: -0.5791 - val_acc: 0.0111\n",
      "Epoch 84/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6302 - acc: 0.0373 - val_loss: -0.5825 - val_acc: 0.0111\n",
      "Epoch 85/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6279 - acc: 0.0373 - val_loss: -0.5842 - val_acc: 0.0074\n",
      "Epoch 86/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6290 - acc: 0.0382 - val_loss: -0.5815 - val_acc: 0.0074\n",
      "Epoch 87/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6297 - acc: 0.0392 - val_loss: -0.5795 - val_acc: 0.0111\n",
      "Epoch 88/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6300 - acc: 0.0402 - val_loss: -0.5829 - val_acc: 0.0148\n",
      "Epoch 89/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6296 - acc: 0.0471 - val_loss: -0.5842 - val_acc: 0.0222\n",
      "Epoch 90/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6297 - acc: 0.0510 - val_loss: -0.5826 - val_acc: 0.0185\n",
      "Epoch 91/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6307 - acc: 0.0500 - val_loss: -0.5810 - val_acc: 0.0148\n",
      "Epoch 92/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6308 - acc: 0.0431 - val_loss: -0.5807 - val_acc: 0.0074\n",
      "Epoch 93/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6312 - acc: 0.0333 - val_loss: -0.5813 - val_acc: 0.0037\n",
      "Epoch 94/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6312 - acc: 0.0353 - val_loss: -0.5815 - val_acc: 0.0148\n",
      "Epoch 95/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6315 - acc: 0.0471 - val_loss: -0.5829 - val_acc: 0.0259\n",
      "Epoch 96/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6312 - acc: 0.0539 - val_loss: -0.5823 - val_acc: 0.0222\n",
      "Epoch 97/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6318 - acc: 0.0500 - val_loss: -0.5796 - val_acc: 0.0074\n",
      "Epoch 98/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6314 - acc: 0.0363 - val_loss: -0.5793 - val_acc: 0.0074\n",
      "Epoch 99/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6317 - acc: 0.0333 - val_loss: -0.5830 - val_acc: 0.0074\n",
      "Epoch 100/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6321 - acc: 0.0324 - val_loss: -0.5838 - val_acc: 0.0074\n",
      "Epoch 101/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6322 - acc: 0.0392 - val_loss: -0.5806 - val_acc: 0.0074\n",
      "Epoch 102/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6318 - acc: 0.0324 - val_loss: -0.5798 - val_acc: 0.0000e+00\n",
      "Epoch 103/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6323 - acc: 0.0324 - val_loss: -0.5818 - val_acc: 0.0074\n",
      "Epoch 104/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6316 - acc: 0.0422 - val_loss: -0.5832 - val_acc: 0.0185\n",
      "Epoch 105/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6318 - acc: 0.0490 - val_loss: -0.5838 - val_acc: 0.0222\n",
      "Epoch 106/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6323 - acc: 0.0510 - val_loss: -0.5833 - val_acc: 0.0148\n",
      "Epoch 107/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6330 - acc: 0.0422 - val_loss: -0.5823 - val_acc: 0.0074\n",
      "Epoch 108/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6330 - acc: 0.0324 - val_loss: -0.5838 - val_acc: 0.0111\n",
      "Epoch 109/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6333 - acc: 0.0363 - val_loss: -0.5861 - val_acc: 0.0037\n",
      "Epoch 110/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6324 - acc: 0.0382 - val_loss: -0.5835 - val_acc: 0.0074\n",
      "Epoch 111/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6336 - acc: 0.0422 - val_loss: -0.5780 - val_acc: 0.0111\n",
      "Epoch 112/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6330 - acc: 0.0471 - val_loss: -0.5796 - val_acc: 0.0185\n",
      "Epoch 113/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6339 - acc: 0.0490 - val_loss: -0.5825 - val_acc: 0.0259\n",
      "Epoch 114/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6347 - acc: 0.0520 - val_loss: -0.5828 - val_acc: 0.0185\n",
      "Epoch 115/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6346 - acc: 0.0510 - val_loss: -0.5837 - val_acc: 0.0185\n",
      "Epoch 116/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6347 - acc: 0.0500 - val_loss: -0.5820 - val_acc: 0.0111\n",
      "Epoch 117/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6356 - acc: 0.0471 - val_loss: -0.5834 - val_acc: 0.0111\n",
      "Epoch 118/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6353 - acc: 0.0471 - val_loss: -0.5829 - val_acc: 0.0185\n",
      "Epoch 119/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6355 - acc: 0.0529 - val_loss: -0.5825 - val_acc: 0.0222\n",
      "Epoch 120/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6363 - acc: 0.0529 - val_loss: -0.5807 - val_acc: 0.0185\n",
      "Epoch 121/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6366 - acc: 0.0569 - val_loss: -0.5827 - val_acc: 0.0185\n",
      "Epoch 122/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6370 - acc: 0.0471 - val_loss: -0.5814 - val_acc: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6374 - acc: 0.0382 - val_loss: -0.5820 - val_acc: 0.0000e+00\n",
      "Epoch 124/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6350 - acc: 0.0422 - val_loss: -0.5819 - val_acc: 0.0037\n",
      "Epoch 125/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6367 - acc: 0.0422 - val_loss: -0.5757 - val_acc: 0.0037\n",
      "Epoch 126/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6352 - acc: 0.0422 - val_loss: -0.5791 - val_acc: 0.0074\n",
      "Epoch 127/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6373 - acc: 0.0402 - val_loss: -0.5832 - val_acc: 0.0222\n",
      "Epoch 128/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6371 - acc: 0.0490 - val_loss: -0.5820 - val_acc: 0.0074\n",
      "Epoch 129/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6378 - acc: 0.0431 - val_loss: -0.5784 - val_acc: 0.0037\n",
      "Epoch 130/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6384 - acc: 0.0412 - val_loss: -0.5800 - val_acc: 0.0037\n",
      "Epoch 131/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6388 - acc: 0.0412 - val_loss: -0.5819 - val_acc: 0.0037\n",
      "Epoch 132/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6391 - acc: 0.0392 - val_loss: -0.5780 - val_acc: 0.0148\n",
      "Epoch 133/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6397 - acc: 0.0539 - val_loss: -0.5770 - val_acc: 0.0148\n",
      "Epoch 134/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6397 - acc: 0.0480 - val_loss: -0.5784 - val_acc: 0.0111\n",
      "Epoch 135/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6397 - acc: 0.0510 - val_loss: -0.5743 - val_acc: 0.0000e+00\n",
      "Epoch 136/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6394 - acc: 0.0412 - val_loss: -0.5719 - val_acc: 0.0000e+00\n",
      "Epoch 137/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6386 - acc: 0.0343 - val_loss: -0.5714 - val_acc: 0.0000e+00\n",
      "Epoch 138/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6392 - acc: 0.0324 - val_loss: -0.5771 - val_acc: 0.0148\n",
      "Epoch 139/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6399 - acc: 0.0500 - val_loss: -0.5776 - val_acc: 0.0222\n",
      "Epoch 140/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6413 - acc: 0.0529 - val_loss: -0.5752 - val_acc: 0.0111\n",
      "Epoch 141/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6409 - acc: 0.0402 - val_loss: -0.5792 - val_acc: 0.0037\n",
      "Epoch 142/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6420 - acc: 0.0363 - val_loss: -0.5772 - val_acc: 0.0074\n",
      "Epoch 143/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6423 - acc: 0.0510 - val_loss: -0.5748 - val_acc: 0.0111\n",
      "Epoch 144/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6422 - acc: 0.0471 - val_loss: -0.5753 - val_acc: 0.0000e+00\n",
      "Epoch 145/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6424 - acc: 0.0451 - val_loss: -0.5724 - val_acc: 0.0000e+00\n",
      "Epoch 146/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6434 - acc: 0.0696 - val_loss: -0.5757 - val_acc: 0.0000e+00\n",
      "Epoch 147/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6441 - acc: 0.0402 - val_loss: -0.5751 - val_acc: 0.0074\n",
      "Epoch 148/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6437 - acc: 0.0471 - val_loss: -0.5755 - val_acc: 0.0074\n",
      "Epoch 149/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6443 - acc: 0.0559 - val_loss: -0.5745 - val_acc: 0.0000e+00\n",
      "Epoch 150/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6453 - acc: 0.0500 - val_loss: -0.5741 - val_acc: 0.0000e+00\n",
      "Epoch 151/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6462 - acc: 0.0373 - val_loss: -0.5753 - val_acc: 0.0000e+00\n",
      "Epoch 152/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6468 - acc: 0.0461 - val_loss: -0.5743 - val_acc: 0.0074\n",
      "Epoch 153/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6469 - acc: 0.0412 - val_loss: -0.5770 - val_acc: 0.0037\n",
      "Epoch 154/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6478 - acc: 0.0441 - val_loss: -0.5752 - val_acc: 0.0111\n",
      "Epoch 155/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6466 - acc: 0.0520 - val_loss: -0.5731 - val_acc: 0.0111\n",
      "Epoch 156/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6483 - acc: 0.0529 - val_loss: -0.5772 - val_acc: 0.0037\n",
      "Epoch 157/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6483 - acc: 0.0422 - val_loss: -0.5725 - val_acc: 0.0037\n",
      "Epoch 158/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6497 - acc: 0.0500 - val_loss: -0.5750 - val_acc: 0.0074\n",
      "Epoch 159/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6488 - acc: 0.0520 - val_loss: -0.5712 - val_acc: 0.0074\n",
      "Epoch 160/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6491 - acc: 0.0529 - val_loss: -0.5719 - val_acc: 0.0074\n",
      "Epoch 161/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6492 - acc: 0.0500 - val_loss: -0.5740 - val_acc: 0.0185\n",
      "Epoch 162/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6498 - acc: 0.0598 - val_loss: -0.5679 - val_acc: 0.0148\n",
      "Epoch 163/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6486 - acc: 0.0520 - val_loss: -0.5699 - val_acc: 0.0148\n",
      "Epoch 164/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6493 - acc: 0.0510 - val_loss: -0.5750 - val_acc: 0.0074\n",
      "Epoch 165/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6497 - acc: 0.0451 - val_loss: -0.5748 - val_acc: 0.0111\n",
      "Epoch 166/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6489 - acc: 0.0431 - val_loss: -0.5748 - val_acc: 0.0037\n",
      "Epoch 167/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6512 - acc: 0.0412 - val_loss: -0.5735 - val_acc: 0.0074\n",
      "Epoch 168/500\n",
      "68/68 [==============================] - 1s 8ms/step - loss: -0.6517 - acc: 0.0471 - val_loss: -0.5737 - val_acc: 0.0185\n",
      "Epoch 169/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6532 - acc: 0.0490 - val_loss: -0.5731 - val_acc: 0.0037\n",
      "Epoch 170/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6534 - acc: 0.0510 - val_loss: -0.5702 - val_acc: 0.0148\n",
      "Epoch 171/500\n",
      "68/68 [==============================] - 1s 8ms/step - loss: -0.6517 - acc: 0.0569 - val_loss: -0.5724 - val_acc: 0.0185\n",
      "Epoch 172/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6549 - acc: 0.0490 - val_loss: -0.5725 - val_acc: 0.0185\n",
      "Epoch 173/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6554 - acc: 0.0480 - val_loss: -0.5679 - val_acc: 0.0148\n",
      "Epoch 174/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6562 - acc: 0.0578 - val_loss: -0.5658 - val_acc: 0.0222\n",
      "Epoch 175/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6559 - acc: 0.0578 - val_loss: -0.5672 - val_acc: 0.0111\n",
      "Epoch 176/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6563 - acc: 0.0490 - val_loss: -0.5645 - val_acc: 0.0111\n",
      "Epoch 177/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6553 - acc: 0.0471 - val_loss: -0.5678 - val_acc: 0.0037\n",
      "Epoch 178/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6536 - acc: 0.0422 - val_loss: -0.5729 - val_acc: 0.0185\n",
      "Epoch 179/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6571 - acc: 0.0529 - val_loss: -0.5728 - val_acc: 0.0037\n",
      "Epoch 180/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6563 - acc: 0.0529 - val_loss: -0.5708 - val_acc: 0.0111\n",
      "Epoch 181/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6553 - acc: 0.0539 - val_loss: -0.5718 - val_acc: 0.0148\n",
      "Epoch 182/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6592 - acc: 0.0608 - val_loss: -0.5741 - val_acc: 0.0074\n",
      "Epoch 183/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6586 - acc: 0.0451 - val_loss: -0.5739 - val_acc: 0.0222\n",
      "Epoch 184/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6596 - acc: 0.0549 - val_loss: -0.5718 - val_acc: 0.0148\n",
      "Epoch 185/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6589 - acc: 0.0569 - val_loss: -0.5714 - val_acc: 0.0148\n",
      "Epoch 186/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6605 - acc: 0.0667 - val_loss: -0.5701 - val_acc: 0.0222\n",
      "Epoch 187/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6625 - acc: 0.0578 - val_loss: -0.5697 - val_acc: 0.0074\n",
      "Epoch 188/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6620 - acc: 0.0490 - val_loss: -0.5673 - val_acc: 0.0185\n",
      "Epoch 189/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6572 - acc: 0.0539 - val_loss: -0.5683 - val_acc: 0.0148\n",
      "Epoch 190/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6590 - acc: 0.0647 - val_loss: -0.5736 - val_acc: 0.0148\n",
      "Epoch 191/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6601 - acc: 0.0480 - val_loss: -0.5678 - val_acc: 0.0074\n",
      "Epoch 192/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6551 - acc: 0.0412 - val_loss: -0.5743 - val_acc: 0.0111\n",
      "Epoch 193/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6607 - acc: 0.0461 - val_loss: -0.5731 - val_acc: 0.0074\n",
      "Epoch 194/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6615 - acc: 0.0480 - val_loss: -0.5699 - val_acc: 0.0074\n",
      "Epoch 195/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6627 - acc: 0.0588 - val_loss: -0.5739 - val_acc: 0.0370\n",
      "Epoch 196/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6652 - acc: 0.0765 - val_loss: -0.5736 - val_acc: 0.0259\n",
      "Epoch 197/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6645 - acc: 0.0627 - val_loss: -0.5715 - val_acc: 0.0185\n",
      "Epoch 198/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6651 - acc: 0.0510 - val_loss: -0.5724 - val_acc: 0.0185\n",
      "Epoch 199/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6676 - acc: 0.0559 - val_loss: -0.5700 - val_acc: 0.0148\n",
      "Epoch 200/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6633 - acc: 0.0549 - val_loss: -0.5734 - val_acc: 0.0333\n",
      "Epoch 201/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6647 - acc: 0.0667 - val_loss: -0.5716 - val_acc: 0.0444\n",
      "Epoch 202/500\n",
      "68/68 [==============================] - 1s 7ms/step - loss: -0.6666 - acc: 0.0598 - val_loss: -0.5666 - val_acc: 0.0074\n",
      "Epoch 203/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6681 - acc: 0.0559 - val_loss: -0.5683 - val_acc: 0.0111\n",
      "Epoch 204/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6695 - acc: 0.0627 - val_loss: -0.5687 - val_acc: 0.0111\n",
      "Epoch 205/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6689 - acc: 0.0461 - val_loss: -0.5653 - val_acc: 0.0296\n",
      "Epoch 206/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6692 - acc: 0.0696 - val_loss: -0.5671 - val_acc: 0.0222\n",
      "Epoch 207/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6668 - acc: 0.0637 - val_loss: -0.5684 - val_acc: 0.0185\n",
      "Epoch 208/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6659 - acc: 0.0451 - val_loss: -0.5666 - val_acc: 0.0111\n",
      "Epoch 209/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6637 - acc: 0.0402 - val_loss: -0.5754 - val_acc: 0.0074\n",
      "Epoch 210/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6653 - acc: 0.0480 - val_loss: -0.5769 - val_acc: 0.0222\n",
      "Epoch 211/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6695 - acc: 0.0647 - val_loss: -0.5702 - val_acc: 0.0185\n",
      "Epoch 212/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6691 - acc: 0.0539 - val_loss: -0.5659 - val_acc: 0.0296\n",
      "Epoch 213/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6707 - acc: 0.0667 - val_loss: -0.5651 - val_acc: 0.0407\n",
      "Epoch 214/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6704 - acc: 0.0755 - val_loss: -0.5700 - val_acc: 0.0333\n",
      "Epoch 215/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6667 - acc: 0.0588 - val_loss: -0.5690 - val_acc: 0.0111\n",
      "Epoch 216/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6708 - acc: 0.0549 - val_loss: -0.5653 - val_acc: 0.0148\n",
      "Epoch 217/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6704 - acc: 0.0471 - val_loss: -0.5722 - val_acc: 0.0185\n",
      "Epoch 218/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6719 - acc: 0.0520 - val_loss: -0.5684 - val_acc: 0.0185\n",
      "Epoch 219/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6739 - acc: 0.0637 - val_loss: -0.5607 - val_acc: 0.0148\n",
      "Epoch 220/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6748 - acc: 0.0716 - val_loss: -0.5623 - val_acc: 0.0185\n",
      "Epoch 221/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6767 - acc: 0.0559 - val_loss: -0.5627 - val_acc: 0.0148\n",
      "Epoch 222/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6766 - acc: 0.0657 - val_loss: -0.5662 - val_acc: 0.0185\n",
      "Epoch 223/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6778 - acc: 0.0745 - val_loss: -0.5670 - val_acc: 0.0222\n",
      "Epoch 224/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6769 - acc: 0.0578 - val_loss: -0.5702 - val_acc: 0.0185\n",
      "Epoch 225/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6776 - acc: 0.0618 - val_loss: -0.5695 - val_acc: 0.0333\n",
      "Epoch 226/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6775 - acc: 0.0588 - val_loss: -0.5690 - val_acc: 0.0185\n",
      "Epoch 227/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6797 - acc: 0.0480 - val_loss: -0.5649 - val_acc: 0.0148\n",
      "Epoch 228/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6785 - acc: 0.0539 - val_loss: -0.5676 - val_acc: 0.0185\n",
      "Epoch 229/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6805 - acc: 0.0667 - val_loss: -0.5699 - val_acc: 0.0333\n",
      "Epoch 230/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6796 - acc: 0.0618 - val_loss: -0.5654 - val_acc: 0.0333\n",
      "Epoch 231/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6796 - acc: 0.0686 - val_loss: -0.5649 - val_acc: 0.0222\n",
      "Epoch 232/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6819 - acc: 0.0539 - val_loss: -0.5689 - val_acc: 0.0074\n",
      "Epoch 233/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6833 - acc: 0.0578 - val_loss: -0.5722 - val_acc: 0.2000\n",
      "Epoch 234/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6825 - acc: 0.2794 - val_loss: -0.5724 - val_acc: 0.0370\n",
      "Epoch 235/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6831 - acc: 0.0559 - val_loss: -0.5679 - val_acc: 0.0370\n",
      "Epoch 236/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6822 - acc: 0.0578 - val_loss: -0.5647 - val_acc: 0.0185\n",
      "Epoch 237/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6794 - acc: 0.0608 - val_loss: -0.5700 - val_acc: 0.0148\n",
      "Epoch 238/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6818 - acc: 0.0706 - val_loss: -0.5691 - val_acc: 0.0259\n",
      "Epoch 239/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6830 - acc: 0.0706 - val_loss: -0.5678 - val_acc: 0.0333\n",
      "Epoch 240/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6850 - acc: 0.0657 - val_loss: -0.5650 - val_acc: 0.0333\n",
      "Epoch 241/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6803 - acc: 0.0686 - val_loss: -0.5675 - val_acc: 0.0259\n",
      "Epoch 242/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6834 - acc: 0.0647 - val_loss: -0.5673 - val_acc: 0.0259\n",
      "Epoch 243/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6801 - acc: 0.0588 - val_loss: -0.5643 - val_acc: 0.0111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6799 - acc: 0.0627 - val_loss: -0.5673 - val_acc: 0.0407\n",
      "Epoch 245/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.6838 - acc: 0.0794 - val_loss: -0.5667 - val_acc: 0.0259\n",
      "Epoch 246/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6834 - acc: 0.0667 - val_loss: -0.5664 - val_acc: 0.0148\n",
      "Epoch 247/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6847 - acc: 0.0510 - val_loss: -0.5688 - val_acc: 0.0185\n",
      "Epoch 248/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6829 - acc: 0.0559 - val_loss: -0.5689 - val_acc: 0.0185\n",
      "Epoch 249/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6841 - acc: 0.0627 - val_loss: -0.5671 - val_acc: 0.0370\n",
      "Epoch 250/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6851 - acc: 0.0676 - val_loss: -0.5657 - val_acc: 0.0222\n",
      "Epoch 251/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6841 - acc: 0.0686 - val_loss: -0.5636 - val_acc: 0.0259\n",
      "Epoch 252/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6876 - acc: 0.0657 - val_loss: -0.5657 - val_acc: 0.0259\n",
      "Epoch 253/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6886 - acc: 0.0745 - val_loss: -0.5643 - val_acc: 0.0259\n",
      "Epoch 254/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6905 - acc: 0.0696 - val_loss: -0.5639 - val_acc: 0.0074\n",
      "Epoch 255/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6891 - acc: 0.0549 - val_loss: -0.5664 - val_acc: 0.0296\n",
      "Epoch 256/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6895 - acc: 0.0598 - val_loss: -0.5678 - val_acc: 0.0296\n",
      "Epoch 257/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6916 - acc: 0.0716 - val_loss: -0.5701 - val_acc: 0.0407\n",
      "Epoch 258/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6921 - acc: 0.0794 - val_loss: -0.5660 - val_acc: 0.0185\n",
      "Epoch 259/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6910 - acc: 0.0755 - val_loss: -0.5647 - val_acc: 0.0148\n",
      "Epoch 260/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6908 - acc: 0.0657 - val_loss: -0.5681 - val_acc: 0.0481\n",
      "Epoch 261/500\n",
      "68/68 [==============================] - 1s 9ms/step - loss: -0.6932 - acc: 0.0765 - val_loss: -0.5658 - val_acc: 0.0370\n",
      "Epoch 262/500\n",
      "68/68 [==============================] - 1s 12ms/step - loss: -0.6899 - acc: 0.0735 - val_loss: -0.5624 - val_acc: 0.0185\n",
      "Epoch 263/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6909 - acc: 0.0696 - val_loss: -0.5634 - val_acc: 0.0185\n",
      "Epoch 264/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6919 - acc: 0.0657 - val_loss: -0.5690 - val_acc: 0.0259\n",
      "Epoch 265/500\n",
      "68/68 [==============================] - 1s 7ms/step - loss: -0.6930 - acc: 0.0676 - val_loss: -0.5683 - val_acc: 0.0370\n",
      "Epoch 266/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6937 - acc: 0.0686 - val_loss: -0.5668 - val_acc: 0.0222\n",
      "Epoch 267/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6909 - acc: 0.0716 - val_loss: -0.5644 - val_acc: 0.0222\n",
      "Epoch 268/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6954 - acc: 0.0588 - val_loss: -0.5602 - val_acc: 0.0222\n",
      "Epoch 269/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6950 - acc: 0.0657 - val_loss: -0.5597 - val_acc: 0.0370\n",
      "Epoch 270/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6944 - acc: 0.0686 - val_loss: -0.5600 - val_acc: 0.0185\n",
      "Epoch 271/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6972 - acc: 0.0716 - val_loss: -0.5609 - val_acc: 0.0222\n",
      "Epoch 272/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6946 - acc: 0.0716 - val_loss: -0.5647 - val_acc: 0.0333\n",
      "Epoch 273/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6983 - acc: 0.0824 - val_loss: -0.5662 - val_acc: 0.0222\n",
      "Epoch 274/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6979 - acc: 0.0794 - val_loss: -0.5646 - val_acc: 0.0222\n",
      "Epoch 275/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.6985 - acc: 0.0696 - val_loss: -0.5652 - val_acc: 0.0333\n",
      "Epoch 276/500\n",
      "68/68 [==============================] - 1s 7ms/step - loss: -0.6998 - acc: 0.0686 - val_loss: -0.5651 - val_acc: 0.0296\n",
      "Epoch 277/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7019 - acc: 0.0804 - val_loss: -0.5660 - val_acc: 0.0333\n",
      "Epoch 278/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7013 - acc: 0.0912 - val_loss: -0.5630 - val_acc: 0.0222\n",
      "Epoch 279/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7027 - acc: 0.0775 - val_loss: -0.5607 - val_acc: 0.0185\n",
      "Epoch 280/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7025 - acc: 0.0765 - val_loss: -0.5615 - val_acc: 0.0370\n",
      "Epoch 281/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7038 - acc: 0.0912 - val_loss: -0.5606 - val_acc: 0.0444\n",
      "Epoch 282/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7024 - acc: 0.0814 - val_loss: -0.5626 - val_acc: 0.0185\n",
      "Epoch 283/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7032 - acc: 0.0676 - val_loss: -0.5573 - val_acc: 0.0148\n",
      "Epoch 284/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7040 - acc: 0.0784 - val_loss: -0.5582 - val_acc: 0.0222\n",
      "Epoch 285/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7034 - acc: 0.0951 - val_loss: -0.5633 - val_acc: 0.0222\n",
      "Epoch 286/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7023 - acc: 0.0745 - val_loss: -0.5607 - val_acc: 0.0185\n",
      "Epoch 287/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.6982 - acc: 0.0706 - val_loss: -0.5583 - val_acc: 0.0185\n",
      "Epoch 288/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7002 - acc: 0.0931 - val_loss: -0.5633 - val_acc: 0.3000\n",
      "Epoch 289/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.6977 - acc: 0.3941 - val_loss: -0.5617 - val_acc: 0.0222\n",
      "Epoch 290/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7039 - acc: 0.0843 - val_loss: -0.5573 - val_acc: 0.0222\n",
      "Epoch 291/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7031 - acc: 0.0804 - val_loss: -0.5586 - val_acc: 0.0222\n",
      "Epoch 292/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7043 - acc: 0.0863 - val_loss: -0.5616 - val_acc: 0.0296\n",
      "Epoch 293/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7036 - acc: 0.0863 - val_loss: -0.5600 - val_acc: 0.1259\n",
      "Epoch 294/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7017 - acc: 0.1314 - val_loss: -0.5554 - val_acc: 0.0333\n",
      "Epoch 295/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7034 - acc: 0.0892 - val_loss: -0.5549 - val_acc: 0.0222\n",
      "Epoch 296/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7047 - acc: 0.0961 - val_loss: -0.5578 - val_acc: 0.0148\n",
      "Epoch 297/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7072 - acc: 0.0833 - val_loss: -0.5598 - val_acc: 0.0148\n",
      "Epoch 298/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7086 - acc: 0.0843 - val_loss: -0.5591 - val_acc: 0.0185\n",
      "Epoch 299/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7080 - acc: 0.0794 - val_loss: -0.5538 - val_acc: 0.0222\n",
      "Epoch 300/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7079 - acc: 0.0706 - val_loss: -0.5558 - val_acc: 0.0185\n",
      "Epoch 301/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7079 - acc: 0.0716 - val_loss: -0.5559 - val_acc: 0.0333\n",
      "Epoch 302/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7082 - acc: 0.0775 - val_loss: -0.5596 - val_acc: 0.0333\n",
      "Epoch 303/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7103 - acc: 0.0873 - val_loss: -0.5617 - val_acc: 0.0222\n",
      "Epoch 304/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7103 - acc: 0.0755 - val_loss: -0.5595 - val_acc: 0.0185\n",
      "Epoch 305/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7099 - acc: 0.0618 - val_loss: -0.5621 - val_acc: 0.0148\n",
      "Epoch 306/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7120 - acc: 0.0922 - val_loss: -0.5544 - val_acc: 0.0296\n",
      "Epoch 307/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7088 - acc: 0.1010 - val_loss: -0.5527 - val_acc: 0.0111\n",
      "Epoch 308/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7085 - acc: 0.0843 - val_loss: -0.5578 - val_acc: 0.0111\n",
      "Epoch 309/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7085 - acc: 0.0569 - val_loss: -0.5625 - val_acc: 0.0222\n",
      "Epoch 310/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7105 - acc: 0.0922 - val_loss: -0.5585 - val_acc: 0.0259\n",
      "Epoch 311/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7117 - acc: 0.1078 - val_loss: -0.5573 - val_acc: 0.0148\n",
      "Epoch 312/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7131 - acc: 0.0735 - val_loss: -0.5529 - val_acc: 0.0074\n",
      "Epoch 313/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7140 - acc: 0.0686 - val_loss: -0.5543 - val_acc: 0.0259\n",
      "Epoch 314/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7160 - acc: 0.0931 - val_loss: -0.5587 - val_acc: 0.0333\n",
      "Epoch 315/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7153 - acc: 0.1029 - val_loss: -0.5569 - val_acc: 0.0148\n",
      "Epoch 316/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7156 - acc: 0.0755 - val_loss: -0.5554 - val_acc: 0.0333\n",
      "Epoch 317/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7138 - acc: 0.0814 - val_loss: -0.5570 - val_acc: 0.0222\n",
      "Epoch 318/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7151 - acc: 0.0863 - val_loss: -0.5584 - val_acc: 0.0222\n",
      "Epoch 319/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7143 - acc: 0.0902 - val_loss: -0.5600 - val_acc: 0.0148\n",
      "Epoch 320/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7133 - acc: 0.0912 - val_loss: -0.5569 - val_acc: 0.0148\n",
      "Epoch 321/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7137 - acc: 0.0775 - val_loss: -0.5526 - val_acc: 0.2074\n",
      "Epoch 322/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7151 - acc: 0.1824 - val_loss: -0.5528 - val_acc: 0.0111\n",
      "Epoch 323/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7145 - acc: 0.1029 - val_loss: -0.5510 - val_acc: 0.0222\n",
      "Epoch 324/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7165 - acc: 0.0892 - val_loss: -0.5565 - val_acc: 0.0259\n",
      "Epoch 325/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7153 - acc: 0.0696 - val_loss: -0.5573 - val_acc: 0.0148\n",
      "Epoch 326/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7147 - acc: 0.0853 - val_loss: -0.5556 - val_acc: 0.0148\n",
      "Epoch 327/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7090 - acc: 0.1029 - val_loss: -0.5578 - val_acc: 0.0148\n",
      "Epoch 328/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7165 - acc: 0.0853 - val_loss: -0.5610 - val_acc: 0.0111\n",
      "Epoch 329/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7183 - acc: 0.0667 - val_loss: -0.5581 - val_acc: 0.0148\n",
      "Epoch 330/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7209 - acc: 0.0775 - val_loss: -0.5521 - val_acc: 0.0407\n",
      "Epoch 331/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7203 - acc: 0.1000 - val_loss: -0.5550 - val_acc: 0.0222\n",
      "Epoch 332/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7162 - acc: 0.0971 - val_loss: -0.5548 - val_acc: 0.0185\n",
      "Epoch 333/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7099 - acc: 0.0931 - val_loss: -0.5577 - val_acc: 0.0222\n",
      "Epoch 334/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7158 - acc: 0.0873 - val_loss: -0.5569 - val_acc: 0.0222\n",
      "Epoch 335/500\n",
      "68/68 [==============================] - 1s 9ms/step - loss: -0.7168 - acc: 0.0912 - val_loss: -0.5493 - val_acc: 0.0296\n",
      "Epoch 336/500\n",
      "68/68 [==============================] - 1s 7ms/step - loss: -0.7161 - acc: 0.0843 - val_loss: -0.5550 - val_acc: 0.0148\n",
      "Epoch 337/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7159 - acc: 0.0980 - val_loss: -0.5591 - val_acc: 0.0148\n",
      "Epoch 338/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7194 - acc: 0.0863 - val_loss: -0.5576 - val_acc: 0.0111\n",
      "Epoch 339/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7197 - acc: 0.0833 - val_loss: -0.5576 - val_acc: 0.0111\n",
      "Epoch 340/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7237 - acc: 0.0922 - val_loss: -0.5545 - val_acc: 0.0259\n",
      "Epoch 341/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7196 - acc: 0.0902 - val_loss: -0.5545 - val_acc: 0.0222\n",
      "Epoch 342/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7226 - acc: 0.0912 - val_loss: -0.5528 - val_acc: 0.0222\n",
      "Epoch 343/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7229 - acc: 0.1069 - val_loss: -0.5531 - val_acc: 0.0185\n",
      "Epoch 344/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7225 - acc: 0.1029 - val_loss: -0.5565 - val_acc: 0.0111\n",
      "Epoch 345/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7216 - acc: 0.0833 - val_loss: -0.5557 - val_acc: 0.0148\n",
      "Epoch 346/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7237 - acc: 0.0892 - val_loss: -0.5588 - val_acc: 0.0185\n",
      "Epoch 347/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7252 - acc: 0.1000 - val_loss: -0.5576 - val_acc: 0.0148\n",
      "Epoch 348/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7259 - acc: 0.1029 - val_loss: -0.5545 - val_acc: 0.0074\n",
      "Epoch 349/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7268 - acc: 0.0951 - val_loss: -0.5507 - val_acc: 0.0148\n",
      "Epoch 350/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7259 - acc: 0.0922 - val_loss: -0.5429 - val_acc: 0.0148\n",
      "Epoch 351/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7236 - acc: 0.0951 - val_loss: -0.5592 - val_acc: 0.0185\n",
      "Epoch 352/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7213 - acc: 0.1098 - val_loss: -0.5593 - val_acc: 0.0222\n",
      "Epoch 353/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7265 - acc: 0.0912 - val_loss: -0.5561 - val_acc: 0.0111\n",
      "Epoch 354/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7267 - acc: 0.0873 - val_loss: -0.5584 - val_acc: 0.0222\n",
      "Epoch 355/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7301 - acc: 0.0922 - val_loss: -0.5573 - val_acc: 0.0111\n",
      "Epoch 356/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7300 - acc: 0.0990 - val_loss: -0.5523 - val_acc: 0.0185\n",
      "Epoch 357/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7286 - acc: 0.0961 - val_loss: -0.5540 - val_acc: 0.0148\n",
      "Epoch 358/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7287 - acc: 0.0892 - val_loss: -0.5509 - val_acc: 0.0111\n",
      "Epoch 359/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7273 - acc: 0.0794 - val_loss: -0.5569 - val_acc: 0.0148\n",
      "Epoch 360/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7273 - acc: 0.1049 - val_loss: -0.5532 - val_acc: 0.0259\n",
      "Epoch 361/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7283 - acc: 0.1108 - val_loss: -0.5558 - val_acc: 0.0148\n",
      "Epoch 362/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7280 - acc: 0.0912 - val_loss: -0.5484 - val_acc: 0.0259\n",
      "Epoch 363/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7251 - acc: 0.0961 - val_loss: -0.5552 - val_acc: 0.0185\n",
      "Epoch 364/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7231 - acc: 0.1098 - val_loss: -0.5524 - val_acc: 0.0222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7277 - acc: 0.1039 - val_loss: -0.5548 - val_acc: 0.0148\n",
      "Epoch 366/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7296 - acc: 0.0892 - val_loss: -0.5559 - val_acc: 0.0148\n",
      "Epoch 367/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7318 - acc: 0.1010 - val_loss: -0.5536 - val_acc: 0.0148\n",
      "Epoch 368/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7311 - acc: 0.1176 - val_loss: -0.5488 - val_acc: 0.0185\n",
      "Epoch 369/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7305 - acc: 0.0892 - val_loss: -0.5548 - val_acc: 0.0259\n",
      "Epoch 370/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7307 - acc: 0.1039 - val_loss: -0.5515 - val_acc: 0.0185\n",
      "Epoch 371/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7293 - acc: 0.0882 - val_loss: -0.5583 - val_acc: 0.0148\n",
      "Epoch 372/500\n",
      "68/68 [==============================] - 1s 7ms/step - loss: -0.7298 - acc: 0.1039 - val_loss: -0.5544 - val_acc: 0.0370\n",
      "Epoch 373/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7300 - acc: 0.1078 - val_loss: -0.5547 - val_acc: 0.0222\n",
      "Epoch 374/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7329 - acc: 0.0941 - val_loss: -0.5527 - val_acc: 0.0148\n",
      "Epoch 375/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7328 - acc: 0.0902 - val_loss: -0.5533 - val_acc: 0.0111\n",
      "Epoch 376/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7335 - acc: 0.0971 - val_loss: -0.5467 - val_acc: 0.0111\n",
      "Epoch 377/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7318 - acc: 0.0902 - val_loss: -0.5555 - val_acc: 0.0148\n",
      "Epoch 378/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7309 - acc: 0.1059 - val_loss: -0.5533 - val_acc: 0.0148\n",
      "Epoch 379/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7305 - acc: 0.0902 - val_loss: -0.5553 - val_acc: 0.0296\n",
      "Epoch 380/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7326 - acc: 0.2059 - val_loss: -0.5514 - val_acc: 0.3037\n",
      "Epoch 381/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7351 - acc: 0.3716 - val_loss: -0.5473 - val_acc: 0.0185\n",
      "Epoch 382/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7324 - acc: 0.1127 - val_loss: -0.5531 - val_acc: 0.0222\n",
      "Epoch 383/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7356 - acc: 0.1118 - val_loss: -0.5529 - val_acc: 0.0259\n",
      "Epoch 384/500\n",
      "68/68 [==============================] - 1s 8ms/step - loss: -0.7343 - acc: 0.1088 - val_loss: -0.5471 - val_acc: 0.0185\n",
      "Epoch 385/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7304 - acc: 0.1039 - val_loss: -0.5570 - val_acc: 0.0259\n",
      "Epoch 386/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7320 - acc: 0.1235 - val_loss: -0.5529 - val_acc: 0.0185\n",
      "Epoch 387/500\n",
      "68/68 [==============================] - 0s 3ms/step - loss: -0.7368 - acc: 0.1000 - val_loss: -0.5590 - val_acc: 0.0259\n",
      "Epoch 388/500\n",
      "68/68 [==============================] - 0s 3ms/step - loss: -0.7367 - acc: 0.1088 - val_loss: -0.5604 - val_acc: 0.0296\n",
      "Epoch 389/500\n",
      "68/68 [==============================] - 0s 3ms/step - loss: -0.7378 - acc: 0.1049 - val_loss: -0.5546 - val_acc: 0.0111\n",
      "Epoch 390/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7381 - acc: 0.1157 - val_loss: -0.5498 - val_acc: 0.0148\n",
      "Epoch 391/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7363 - acc: 0.1039 - val_loss: -0.5576 - val_acc: 0.0259\n",
      "Epoch 392/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7367 - acc: 0.1078 - val_loss: -0.5528 - val_acc: 0.0222\n",
      "Epoch 393/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7356 - acc: 0.1088 - val_loss: -0.5578 - val_acc: 0.0185\n",
      "Epoch 394/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7309 - acc: 0.1039 - val_loss: -0.5572 - val_acc: 0.0111\n",
      "Epoch 395/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7346 - acc: 0.1147 - val_loss: -0.5558 - val_acc: 0.0111\n",
      "Epoch 396/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7301 - acc: 0.0971 - val_loss: -0.5534 - val_acc: 0.0148\n",
      "Epoch 397/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7305 - acc: 0.0725 - val_loss: -0.5576 - val_acc: 0.0333\n",
      "Epoch 398/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7349 - acc: 0.1167 - val_loss: -0.5532 - val_acc: 0.0296\n",
      "Epoch 399/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7329 - acc: 0.1235 - val_loss: -0.5494 - val_acc: 0.0185\n",
      "Epoch 400/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7324 - acc: 0.1137 - val_loss: -0.5604 - val_acc: 0.0259\n",
      "Epoch 401/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7321 - acc: 0.1118 - val_loss: -0.5585 - val_acc: 0.0407\n",
      "Epoch 402/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7359 - acc: 0.1127 - val_loss: -0.5544 - val_acc: 0.0370\n",
      "Epoch 403/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7353 - acc: 0.1069 - val_loss: -0.5486 - val_acc: 0.0111\n",
      "Epoch 404/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7343 - acc: 0.0882 - val_loss: -0.5532 - val_acc: 0.0185\n",
      "Epoch 405/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7356 - acc: 0.0931 - val_loss: -0.5528 - val_acc: 0.0370\n",
      "Epoch 406/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7326 - acc: 0.1147 - val_loss: -0.5559 - val_acc: 0.0333\n",
      "Epoch 407/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7364 - acc: 0.1137 - val_loss: -0.5550 - val_acc: 0.0370\n",
      "Epoch 408/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7404 - acc: 0.1127 - val_loss: -0.5532 - val_acc: 0.0259\n",
      "Epoch 409/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7389 - acc: 0.1098 - val_loss: -0.5527 - val_acc: 0.0259\n",
      "Epoch 410/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7397 - acc: 0.1157 - val_loss: -0.5508 - val_acc: 0.0222\n",
      "Epoch 411/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7399 - acc: 0.0980 - val_loss: -0.5537 - val_acc: 0.0259\n",
      "Epoch 412/500\n",
      "68/68 [==============================] - 1s 8ms/step - loss: -0.7414 - acc: 0.1216 - val_loss: -0.5532 - val_acc: 0.0259\n",
      "Epoch 413/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7427 - acc: 0.1176 - val_loss: -0.5503 - val_acc: 0.0074\n",
      "Epoch 414/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7380 - acc: 0.0775 - val_loss: -0.5518 - val_acc: 0.0148\n",
      "Epoch 415/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7415 - acc: 0.1020 - val_loss: -0.5547 - val_acc: 0.0370\n",
      "Epoch 416/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7393 - acc: 0.1049 - val_loss: -0.5532 - val_acc: 0.0296\n",
      "Epoch 417/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7416 - acc: 0.1167 - val_loss: -0.5506 - val_acc: 0.0111\n",
      "Epoch 418/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7407 - acc: 0.1176 - val_loss: -0.5577 - val_acc: 0.0333\n",
      "Epoch 419/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7367 - acc: 0.1206 - val_loss: -0.5603 - val_acc: 0.0407\n",
      "Epoch 420/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7402 - acc: 0.1039 - val_loss: -0.5537 - val_acc: 0.0148\n",
      "Epoch 421/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7388 - acc: 0.0833 - val_loss: -0.5579 - val_acc: 0.0815\n",
      "Epoch 422/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7424 - acc: 0.2049 - val_loss: -0.5525 - val_acc: 0.0222\n",
      "Epoch 423/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7388 - acc: 0.1206 - val_loss: -0.5559 - val_acc: 0.0185\n",
      "Epoch 424/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7303 - acc: 0.1078 - val_loss: -0.5571 - val_acc: 0.1704\n",
      "Epoch 425/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7369 - acc: 0.1696 - val_loss: -0.5537 - val_acc: 0.0296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7383 - acc: 0.1137 - val_loss: -0.5525 - val_acc: 0.0222\n",
      "Epoch 427/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7352 - acc: 0.1255 - val_loss: -0.5483 - val_acc: 0.0259\n",
      "Epoch 428/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7351 - acc: 0.1118 - val_loss: -0.5551 - val_acc: 0.0222\n",
      "Epoch 429/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7385 - acc: 0.1265 - val_loss: -0.5507 - val_acc: 0.0296\n",
      "Epoch 430/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7394 - acc: 0.1108 - val_loss: -0.5470 - val_acc: 0.0148\n",
      "Epoch 431/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7432 - acc: 0.1157 - val_loss: -0.5567 - val_acc: 0.0185\n",
      "Epoch 432/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7366 - acc: 0.1167 - val_loss: -0.5511 - val_acc: 0.0222\n",
      "Epoch 433/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7421 - acc: 0.1127 - val_loss: -0.5545 - val_acc: 0.0222\n",
      "Epoch 434/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7444 - acc: 0.1167 - val_loss: -0.5579 - val_acc: 0.0333\n",
      "Epoch 435/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7444 - acc: 0.1216 - val_loss: -0.5519 - val_acc: 0.0333\n",
      "Epoch 436/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7431 - acc: 0.1088 - val_loss: -0.5534 - val_acc: 0.0259\n",
      "Epoch 437/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7439 - acc: 0.1137 - val_loss: -0.5544 - val_acc: 0.0148\n",
      "Epoch 438/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7461 - acc: 0.1108 - val_loss: -0.5503 - val_acc: 0.0222\n",
      "Epoch 439/500\n",
      "68/68 [==============================] - 1s 7ms/step - loss: -0.7443 - acc: 0.1157 - val_loss: -0.5553 - val_acc: 0.0222\n",
      "Epoch 440/500\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7465 - acc: 0.1333 - val_loss: -0.5544 - val_acc: 0.2519\n",
      "Epoch 441/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7486 - acc: 0.3873 - val_loss: -0.5528 - val_acc: 0.0259\n",
      "Epoch 442/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7475 - acc: 0.1157 - val_loss: -0.5559 - val_acc: 0.0259\n",
      "Epoch 443/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7487 - acc: 0.1294 - val_loss: -0.5519 - val_acc: 0.0222\n",
      "Epoch 444/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7483 - acc: 0.1304 - val_loss: -0.5569 - val_acc: 0.0222\n",
      "Epoch 445/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7493 - acc: 0.1363 - val_loss: -0.5528 - val_acc: 0.0259\n",
      "Epoch 446/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7484 - acc: 0.1245 - val_loss: -0.5512 - val_acc: 0.0259\n",
      "Epoch 447/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7471 - acc: 0.1176 - val_loss: -0.5493 - val_acc: 0.0111\n",
      "Epoch 448/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7483 - acc: 0.1549 - val_loss: -0.5553 - val_acc: 0.2704\n",
      "Epoch 449/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7472 - acc: 0.3343 - val_loss: -0.5514 - val_acc: 0.0222\n",
      "Epoch 450/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7501 - acc: 0.1216 - val_loss: -0.5472 - val_acc: 0.0259\n",
      "Epoch 451/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7512 - acc: 0.1216 - val_loss: -0.5526 - val_acc: 0.0296\n",
      "Epoch 452/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7517 - acc: 0.1216 - val_loss: -0.5516 - val_acc: 0.0259\n",
      "Epoch 453/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7521 - acc: 0.1373 - val_loss: -0.5540 - val_acc: 0.0333\n",
      "Epoch 454/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7521 - acc: 0.1412 - val_loss: -0.5530 - val_acc: 0.0370\n",
      "Epoch 455/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7533 - acc: 0.1304 - val_loss: -0.5505 - val_acc: 0.0815\n",
      "Epoch 456/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7529 - acc: 0.1578 - val_loss: -0.5521 - val_acc: 0.0185\n",
      "Epoch 457/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7529 - acc: 0.1225 - val_loss: -0.5491 - val_acc: 0.0222\n",
      "Epoch 458/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7529 - acc: 0.1294 - val_loss: -0.5496 - val_acc: 0.0481\n",
      "Epoch 459/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7525 - acc: 0.1343 - val_loss: -0.5504 - val_acc: 0.0370\n",
      "Epoch 460/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7524 - acc: 0.1353 - val_loss: -0.5516 - val_acc: 0.0222\n",
      "Epoch 461/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7530 - acc: 0.1167 - val_loss: -0.5574 - val_acc: 0.0185\n",
      "Epoch 462/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7522 - acc: 0.1304 - val_loss: -0.5467 - val_acc: 0.0296\n",
      "Epoch 463/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7401 - acc: 0.1196 - val_loss: -0.5565 - val_acc: 0.0296\n",
      "Epoch 464/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7358 - acc: 0.1294 - val_loss: -0.5554 - val_acc: 0.0259\n",
      "Epoch 465/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7381 - acc: 0.1049 - val_loss: -0.5573 - val_acc: 0.0222\n",
      "Epoch 466/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7469 - acc: 0.1078 - val_loss: -0.5582 - val_acc: 0.0333\n",
      "Epoch 467/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7490 - acc: 0.1373 - val_loss: -0.5465 - val_acc: 0.0296\n",
      "Epoch 468/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7502 - acc: 0.1304 - val_loss: -0.5505 - val_acc: 0.0148\n",
      "Epoch 469/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7534 - acc: 0.1176 - val_loss: -0.5501 - val_acc: 0.0259\n",
      "Epoch 470/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7527 - acc: 0.1314 - val_loss: -0.5540 - val_acc: 0.0333\n",
      "Epoch 471/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7533 - acc: 0.1284 - val_loss: -0.5517 - val_acc: 0.0148\n",
      "Epoch 472/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7546 - acc: 0.1186 - val_loss: -0.5541 - val_acc: 0.0296\n",
      "Epoch 473/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7543 - acc: 0.1235 - val_loss: -0.5549 - val_acc: 0.0222\n",
      "Epoch 474/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7551 - acc: 0.1265 - val_loss: -0.5498 - val_acc: 0.0148\n",
      "Epoch 475/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7530 - acc: 0.1049 - val_loss: -0.5446 - val_acc: 0.0333\n",
      "Epoch 476/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7536 - acc: 0.1225 - val_loss: -0.5481 - val_acc: 0.0444\n",
      "Epoch 477/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7518 - acc: 0.1343 - val_loss: -0.5550 - val_acc: 0.0111\n",
      "Epoch 478/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7513 - acc: 0.1088 - val_loss: -0.5550 - val_acc: 0.0222\n",
      "Epoch 479/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7534 - acc: 0.1108 - val_loss: -0.5534 - val_acc: 0.0370\n",
      "Epoch 480/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7541 - acc: 0.1363 - val_loss: -0.5499 - val_acc: 0.0259\n",
      "Epoch 481/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7562 - acc: 0.1284 - val_loss: -0.5510 - val_acc: 0.0296\n",
      "Epoch 482/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7546 - acc: 0.1294 - val_loss: -0.5506 - val_acc: 0.0296\n",
      "Epoch 483/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7563 - acc: 0.2441 - val_loss: -0.5485 - val_acc: 0.2852\n",
      "Epoch 484/500\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7538 - acc: 0.3794 - val_loss: -0.5540 - val_acc: 0.0148\n",
      "Epoch 485/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7555 - acc: 0.1235 - val_loss: -0.5536 - val_acc: 0.0222\n",
      "Epoch 486/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7550 - acc: 0.1343 - val_loss: -0.5502 - val_acc: 0.0296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7549 - acc: 0.1324 - val_loss: -0.5572 - val_acc: 0.0222\n",
      "Epoch 488/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7536 - acc: 0.1225 - val_loss: -0.5531 - val_acc: 0.0222\n",
      "Epoch 489/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7528 - acc: 0.1127 - val_loss: -0.5498 - val_acc: 0.0444\n",
      "Epoch 490/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7526 - acc: 0.1343 - val_loss: -0.5525 - val_acc: 0.0407\n",
      "Epoch 491/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7541 - acc: 0.1373 - val_loss: -0.5503 - val_acc: 0.0407\n",
      "Epoch 492/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7534 - acc: 0.1363 - val_loss: -0.5496 - val_acc: 0.0370\n",
      "Epoch 493/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7546 - acc: 0.1265 - val_loss: -0.5465 - val_acc: 0.0259\n",
      "Epoch 494/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7517 - acc: 0.1333 - val_loss: -0.5561 - val_acc: 0.0259\n",
      "Epoch 495/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7567 - acc: 0.1284 - val_loss: -0.5459 - val_acc: 0.0222\n",
      "Epoch 496/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7541 - acc: 0.1304 - val_loss: -0.5552 - val_acc: 0.0519\n",
      "Epoch 497/500\n",
      "68/68 [==============================] - 0s 4ms/step - loss: -0.7569 - acc: 0.1373 - val_loss: -0.5463 - val_acc: 0.0259\n",
      "Epoch 498/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7551 - acc: 0.1275 - val_loss: -0.5540 - val_acc: 0.0185\n",
      "Epoch 499/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7494 - acc: 0.1343 - val_loss: -0.5510 - val_acc: 0.0333\n",
      "Epoch 500/500\n",
      "68/68 [==============================] - 0s 5ms/step - loss: -0.7517 - acc: 0.1333 - val_loss: -0.5551 - val_acc: 0.0444\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, epochs=500, validation_data=(x_test, y_test))\n",
    "model.save('LSTMBR_500.h5');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f215ba94978>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f215ba947b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sridevi', 0.7175910472869873),\n",
       " ('sonâmbulo', 0.6549521088600159),\n",
       " ('parahybunensis', 0.5860856175422668),\n",
       " ('estrellanus', 0.629959225654602),\n",
       " ('oligochaeta', 0.689191460609436),\n",
       " ('duodenale', 0.6419933438301086),\n",
       " ('oligochaeta', 0.6573616862297058),\n",
       " ('duodenale', 0.6444982886314392),\n",
       " ('proxies', 0.6501667499542236),\n",
       " ('duodenale', 0.6440722346305847),\n",
       " ('duodenale', 0.6400073766708374),\n",
       " ('duodenale', 0.6381053328514099),\n",
       " ('duodenale', 0.6438155174255371),\n",
       " ('oligochaeta', 0.6419497728347778),\n",
       " ('proxies', 0.6412787437438965)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "[w2v.most_similar([predictions[10][i]])[0] for i in range(15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
